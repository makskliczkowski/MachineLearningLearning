{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16857467938295893800\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5085921280\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9900494521451828435\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import pandas as pd\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _image_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _image_handler\n",
    "from skimage.io import *\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "from skimage.util import img_as_ubyte\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def image_fromURL_toGrey(x, size, prnt, directory):\n",
    "    # Here we read the file from the url, convert it to greyscale of size\n",
    "    # given by the user, check if it's aviable and if it's not return nan\n",
    "    # temp = np.array(x)\n",
    "    dir = directory\n",
    "\n",
    "    def applier(url, size2=size, shall_print=prnt):\n",
    "        url2 = (url[:-4] + 'jpg').replace('html', 'detail')\n",
    "        # img = Image.open(requests.get(url2, stream=True).raw).convert('L')\n",
    "        try:\n",
    "            tempname = url2.split('/')\n",
    "            filename = tempname[-2] + '_' + tempname[-1]\n",
    "            if os.path.isfile(dir + \"/\" + filename):\n",
    "                return filename\n",
    "            if shall_print:\n",
    "                img1 = imread(url2, as_gray=False)\n",
    "                img1 = cv2.resize(img1, (size2, size2), interpolation=cv2.INTER_CUBIC)\n",
    "                img1 = img_as_ubyte(img1)\n",
    "                imsave(dir + \"/\" + filename, img1)\n",
    "            if os.path.isfile(dir + \"/\" + filename):\n",
    "                return filename\n",
    "            else:\n",
    "                return np.nan\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            return np.nan\n",
    "\n",
    "    # print(temp)\n",
    "    return np.vectorize(applier)(x)\n",
    "\n",
    "\n",
    "#\n",
    "def putImageToDb_CV2(x, directory):\n",
    "    # @numba.jit\n",
    "    def applier(url):\n",
    "        url2 = (url[:-4] + 'jpg').replace('html', 'detail')\n",
    "        dir = directory\n",
    "        tempname = url2.split('/')\n",
    "        filename = tempname[-2] + '_' + tempname[-1]\n",
    "        try:\n",
    "            image = cv2.imread(dir + '/' + filename)\n",
    "            return image\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    return np.vectorize(applier)(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  _database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------- _database\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import swifter\n",
    "\n",
    "def createImageDatabase(dir, im_dir, download=False, want_whole_im=False, howmany=20000):\n",
    "    db = pd.read_excel(dir, nrows=howmany)\n",
    "    db['URL'] = db['URL'].where(db['URL'].str.endswith('html')).dropna()\n",
    "    # db['URL'] = db.swifter.apply(lambda x: image_fromURL_toGrey(x['URL'], 128), axis=1, raw=True)\n",
    "    if not want_whole_im:\n",
    "        if download or len(os.listdir(im_dir)) == 0:\n",
    "            # we put files into database, if the files are downloaded yet we can skip it\n",
    "            print('Downloading files and saving them in ' + im_dir + '\\n')\n",
    "            db['URL'] = db['URL'].swifter.apply(image_fromURL_toGrey, args=[128, True, im_dir])\n",
    "\n",
    "        else:\n",
    "            # we print the files to the folder, and put them into database, if the files are downloaded yet we can\n",
    "            # skip it\n",
    "            print('Taking files and just putting their names in the dataframe\\n')\n",
    "            db['URL'] = db['URL'].swifter.apply(image_fromURL_toGrey, args=[128, False, im_dir])\n",
    "        db = (db.dropna()\n",
    "              .rename(columns={'URL': 'Images'}))\n",
    "    else:\n",
    "        print('Putting images from folder ' + im_dir + ' to dataframe\\n')\n",
    "        db['Image'] = (db['URL'].swifter.apply(putImageToDb_CV2, args=[im_dir])\n",
    "                       .dropna())\n",
    "    print('Finished checking folder\\n')\n",
    "    db['ID'] = db.groupby(['TYPE']).ngroup()\n",
    "    # print(db)\n",
    "    # db.set_index('Images', inplace=True)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _network\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHistory(history):\n",
    "    #val_acc = history.history['val_acc']\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "def createModel(df, dir, savename, columns,types_num, epo=10, batch=32):\n",
    "    DATASET_LOCATION = dir\n",
    "    BATCH_SIZE = batch\n",
    "    IMAGE_SIZE = (128, 128)\n",
    "    INPUT_SHAPE = (128, 128, 3)\n",
    "    EPOCHS = epo\n",
    "    conv_base = VGG19(weights = 'imagenet', include_top=False, input_shape = (128, 128, 3))\n",
    "    conv_base.trainable = False\n",
    "    # Tworzymy bazę na podstawie conv modelu bez górnego klasyfikatora\n",
    "    \n",
    "    # Instantiating a Convolutional Neural Network (CNN) Classifier\n",
    "    model = Sequential()\n",
    "    # biggest -----------\n",
    "    #--------vectoor\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "    # ------frozen base-------------\n",
    "    model.add(conv_base)\n",
    "    \n",
    "    #model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu', input_shape=INPUT_SHAPE))\n",
    "    #model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
    "    #model.add(MaxPooling2D(2, 2))\n",
    "    #model.add(Conv2D(64, (3, 3), activation= 'relu',padding='same'))\n",
    "    #model.add(Conv2D(64, (3, 3), activation= 'relu',padding='same'))\n",
    "    #model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    #model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(2, 2))\n",
    "    # conv_base.summary()\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    #model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(types_num, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.adam(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    print('Initialized model\\n')\n",
    "    # separate in training and testing\n",
    "    train_df, test_df = train_test_split(df, test_size=0.25, random_state=40)\n",
    "    # data augmentation - to provide more samples\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "    )\n",
    "    # cannot change validation data!\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "    print('Created data augmentation method, now we have more data! Cool huh?\\n')\n",
    "    # read files of a difrectory using flow from dataframe\n",
    "    # FIRST FOR TRAIN SECOND FOR TEST\n",
    "    try:\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "            train_df,\n",
    "            DATASET_LOCATION,\n",
    "            x_col=columns[0],\n",
    "            y_col=columns[1],\n",
    "            target_size=IMAGE_SIZE,\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        print('Created set for teaching\\n')\n",
    "        test_generator = test_datagen.flow_from_dataframe(\n",
    "            test_df,\n",
    "            DATASET_LOCATION,\n",
    "            x_col=columns[0],\n",
    "            y_col=columns[1],\n",
    "            target_size=IMAGE_SIZE,\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        print('Created set for validation\\n')\n",
    "        # NOW WE TRAIN THE MODEL\n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=test_df.shape[0] // BATCH_SIZE,\n",
    "            steps_per_epoch=train_df.shape[0] // BATCH_SIZE,\n",
    "            verbose=1,\n",
    "        )\n",
    "        print('Trained frozen model. Now unfroze some\\n')\n",
    "        set_trainable = False\n",
    "        for layer in conv_base.layers:\n",
    "            if layer.name == 'block5_conv1':\n",
    "                set_trainable = True\n",
    "            if set_trainable:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "                \n",
    "            \n",
    "        model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.RMSprop(lr=1e-5),\n",
    "        metrics=[\"accuracy\"],\n",
    "        )\n",
    "                \n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=test_df.shape[0] // BATCH_SIZE,\n",
    "            steps_per_epoch=train_df.shape[0] // BATCH_SIZE,\n",
    "            verbose=1,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Trained model\\n')\n",
    "        # save model and architecture to single file\n",
    "        model.save(savename)\n",
    "        print(\"Saved model to disk\\n\")\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(test_df, test_dir, name, columns):\n",
    "    IMAGE_SIZE = (128, 128)\n",
    "    INPUT_SHAPE = (128, 128, 3)\n",
    "    # load model\n",
    "    model = load_model(name)\n",
    "    print('Loaded the model\\n')\n",
    "    # summarize model.\n",
    "    model.summary()\n",
    "    # test generator\n",
    "    batches = 1\n",
    "    sample_test_generator = ImageDataGenerator(rescale=1.0/255).flow_from_dataframe(\n",
    "        test_df,\n",
    "        test_dir,\n",
    "        x_col=columns[0],\n",
    "        y_col=columns[1],\n",
    "        target_size=IMAGE_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        #batch_size=batches,\n",
    "    )\n",
    "    label_map = (sample_test_generator.class_indices)\n",
    "    print('Created test generator\\n')\n",
    "    # predict\n",
    "    filenames = sample_test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    #print('Len of filenames is:' + nb_samples)\n",
    "    predict = model.predict_generator(sample_test_generator,np.ceil(nb_samples/batches))\n",
    "    return predict, label_map\n",
    "    # score = model.evaluate_generator(sample_test_generator)\n",
    "    # print(\"Accuracy = \", score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/catalogMy.xlsx'\n",
    "test_dir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/new.xlsx'\n",
    "learnImDir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/Images'\n",
    "testImDir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/ImagesTest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files and saving them in D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/ImagesTest\n",
      "\n",
      "Finished checking folder\n",
      "\n",
      "Taking files and just putting their names in the dataframe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPd = createImageDatabase(test_dir, testImDir, True, howmany = 2000)\n",
    "learnPd = createImageDatabase(dir, learnImDir, False, howmany = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn df is :\n",
      "                   Images      FORM  ID\n",
      "0    aachen_j_couple.jpg  painting   0\n",
      "1    aachen_k_couple.jpg  painting   0\n",
      "2    aachen_portrai4.jpg  painting   0\n",
      "3     aachen_z_scene.jpg  painting   0\n",
      "4         adam1_hunt.jpg  painting   0\n",
      "5       aertsen_cook.jpg  painting   0\n",
      "6      aertsen_cook1.jpg  painting   0\n",
      "7   aertsen_egg-danc.jpg  painting   0\n",
      "8     aertsen_market.jpg  painting   0\n",
      "9    aertsen_market1.jpg  painting   0\n",
      "10  aertsen_marketsc.jpg  painting   0\n",
      "11  aertsen_marketsd.jpg  painting   0\n",
      "12  aertsen_meatsell.jpg  painting   0\n",
      "13  aertsen_merry_co.jpg  painting   0\n",
      "14   aertsen_pancake.jpg  painting   0\n",
      "15  aertsen_peasant1.jpg  painting   0\n",
      "16  aertsen_peasant2.jpg  painting   0\n",
      "17  aertsen_vendor_f.jpg  painting   0\n",
      "18   agasse_playgrou.jpg  painting   0\n",
      "19     aken_conversa.jpg  painting   0\n",
      "Test df is :\n",
      "                    Images          FORM  ID\n",
      "0     mochi_o_players.jpg     sculpture   0\n",
      "1    cordier_sterling.jpg     sculpture   1\n",
      "2          1_211giamb.jpg     sculpture   1\n",
      "3          1_221giamb.jpg     sculpture   1\n",
      "4          1_22giambo.jpg     sculpture   1\n",
      "5          2_542giamb.jpg     sculpture   1\n",
      "6     pierino_samson1.jpg     sculpture   1\n",
      "7     pierino_samson2.jpg     sculpture   1\n",
      "8   rusconi1_collegio.jpg  architecture   2\n",
      "9     father_principi.jpg     sculpture   2\n",
      "10           1_ztomb2.jpg     sculpture   2\n",
      "11  montorso_messina1.jpg     sculpture   3\n",
      "12         4_y_athena.jpg     sculpture   4\n",
      "13         1_hercules.jpg     sculpture   4\n",
      "14         3_hercules.jpg     sculpture   4\n",
      "15            3_leda1.jpg     sculpture   4\n",
      "16           3_winter.jpg     sculpture   4\n",
      "17   aspetti_hercule1.jpg     sculpture   4\n",
      "18   aspetti_hercule2.jpg     sculpture   4\n",
      "19   aspetti_hercule3.jpg     sculpture   4\n"
     ]
    }
   ],
   "source": [
    "train_cols = ['Images','FORM']\n",
    "\n",
    "print('Learn df is :\\n', learnPd[['Images', train_cols[1], 'ID']].head(20))\n",
    "print('Test df is :\\n', testPd[['Images', train_cols[1], 'ID']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Images      FORM  ID\n",
      "0  aachen_k_couple.jpg  painting   9\n",
      "1  aachen_portrai4.jpg  painting   9\n",
      "2  aachen_j_couple.jpg  painting   9\n",
      "3   aachen_z_scene.jpg  painting   9\n",
      "4  aachen_davidbat.jpg  painting   9\n",
      "{'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12}\n"
     ]
    }
   ],
   "source": [
    "db = learnPd.loc[:,train_cols]\n",
    "db['ID'] = db.groupby(train_cols[1]).ngroup()\n",
    "print(db.head())\n",
    "dic = (db.groupby(train_cols[1]).first())['ID'].to_dict()\n",
    "print(dic)\n",
    "types_num = len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a11789e9d3b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearnPd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearnImDir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'from_imagenet_FORM.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtypes_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'createModel' is not defined"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "# history = createModel(learnPd, learnImDir,'from_imagenet_FORM.h5',train_cols,types_num, epo=10, batch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "printHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model\n",
      "\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 13)                845       \n",
      "=================================================================\n",
      "Total params: 24,367,821\n",
      "Trainable params: 13,782,669\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n",
      "Found 2000 validated image filenames belonging to 13 classes.\n",
      "Created test generator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict, label_map_test = testModel(testPd, testImDir,'from_imagenet_FORM.h5',train_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9994 validated image filenames belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"Images\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "# check the indices and their categories on original dataset\n",
    "def check_orig_labels(learnPd, learnImDir ):\n",
    "    train_generator = ImageDataGenerator(rescale=1.0/255).flow_from_dataframe(\n",
    "            learnPd,\n",
    "            learnImDir,\n",
    "            x_col=train_cols[0],\n",
    "            y_col=train_cols[1],\n",
    "            target_size=(128,128,3),\n",
    "            class_mode=\"categorical\",\n",
    "        )\n",
    "    return (train_generator.class_indices)\n",
    "label_map_orig = check_orig_labels(learnPd, learnImDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_map_orig)\n",
    "print(label_map_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12} {'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12}\n"
     ]
    }
   ],
   "source": [
    "def change_keys_from_org_to_new(label_map_orig,label_map_test):\n",
    "    res = {} \n",
    "    for key, val in label_map_orig.items():\n",
    "        #label_map_test[key] = label_map_orig[key]\n",
    "        res[val] = key\n",
    "    print(label_map_orig,label_map_test)\n",
    "    return res\n",
    "\n",
    "final_dic = change_keys_from_org_to_new(label_map_orig,label_map_test  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'architecture', 1: 'ceramics', 2: 'furniture', 3: 'glassware', 4: 'graphics', 5: 'illumination', 6: 'metalwork', 7: 'mosaic', 8: 'others', 9: 'painting', 10: 'sculpture', 11: 'stained-glass', 12: 'tapestry'}\n"
     ]
    }
   ],
   "source": [
    "print(final_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check = testPd.loc[:,train_cols]\n",
    "test_check['ID'] = test_check.groupby(train_cols[1]).ngroup()\n",
    "\n",
    "max_index = np.argmax(predict, axis=1)     \n",
    "print(max_index)\n",
    "test_check['INDEX_PREDICTED'] = max_index\n",
    "\n",
    "test_check['CATEGORY_PREDICTED'] = test_check['INDEX_PREDICTED'].map(lambda a: final_dic[a])\n",
    "\n",
    "good_checks = test_check[test_check['FORM'] == test_check['CATEGORY_PREDICTED']]\n",
    "print(test_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
