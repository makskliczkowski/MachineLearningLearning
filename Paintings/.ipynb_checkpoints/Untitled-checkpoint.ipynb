{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10059816142087661658\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5085921280\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16081629962120580939\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import pandas as pd\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _image_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _image_handler\n",
    "from skimage.io import *\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "from skimage.util import img_as_ubyte\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def image_fromURL_toGrey(x, size, prnt, directory):\n",
    "    # Here we read the file from the url, convert it to greyscale of size\n",
    "    # given by the user, check if it's aviable and if it's not return nan\n",
    "    # temp = np.array(x)\n",
    "    dir = directory\n",
    "\n",
    "    def applier(url, size2=size, shall_print=prnt):\n",
    "        url2 = (url[:-4] + 'jpg').replace('html', 'detail')\n",
    "        # img = Image.open(requests.get(url2, stream=True).raw).convert('L')\n",
    "        try:\n",
    "            tempname = url2.split('/')\n",
    "            filename = tempname[-2] + '_' + tempname[-1]\n",
    "            if os.path.isfile(dir + \"/\" + filename):\n",
    "                return filename\n",
    "            if shall_print:\n",
    "                img1 = imread(url2, as_gray=False)\n",
    "                img1 = cv2.resize(img1, (size2, size2), interpolation=cv2.INTER_CUBIC)\n",
    "                img1 = img_as_ubyte(img1)\n",
    "                imsave(dir + \"/\" + filename, img1)\n",
    "            if os.path.isfile(dir + \"/\" + filename):\n",
    "                return filename\n",
    "            else:\n",
    "                return np.nan\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            return np.nan\n",
    "\n",
    "    # print(temp)\n",
    "    return np.vectorize(applier)(x)\n",
    "\n",
    "\n",
    "#\n",
    "def putImageToDb_CV2(x, directory):\n",
    "    # @numba.jit\n",
    "    def applier(url):\n",
    "        url2 = (url[:-4] + 'jpg').replace('html', 'detail')\n",
    "        dir = directory\n",
    "        tempname = url2.split('/')\n",
    "        filename = tempname[-2] + '_' + tempname[-1]\n",
    "        try:\n",
    "            image = cv2.imread(dir + '/' + filename)\n",
    "            return image\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    return np.vectorize(applier)(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  _database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------- _database\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import swifter\n",
    "\n",
    "def createImageDatabase(dir, im_dir, download=False, want_whole_im=False, howmany=20000):\n",
    "    db = pd.read_excel(dir, nrows=howmany)\n",
    "    db['URL'] = db['URL'].where(db['URL'].str.endswith('html')).dropna()\n",
    "    # db['URL'] = db.swifter.apply(lambda x: image_fromURL_toGrey(x['URL'], 128), axis=1, raw=True)\n",
    "    if not want_whole_im:\n",
    "        if download or len(os.listdir(im_dir)) == 0:\n",
    "            # we put files into database, if the files are downloaded yet we can skip it\n",
    "            print('Downloading files and saving them in ' + im_dir + '\\n')\n",
    "            db['URL'] = db['URL'].swifter.apply(image_fromURL_toGrey, args=[128, True, im_dir])\n",
    "\n",
    "        else:\n",
    "            # we print the files to the folder, and put them into database, if the files are downloaded yet we can\n",
    "            # skip it\n",
    "            print('Taking files and just putting their names in the dataframe\\n')\n",
    "            db['URL'] = db['URL'].swifter.apply(image_fromURL_toGrey, args=[128, False, im_dir])\n",
    "        db = (db.dropna()\n",
    "              .rename(columns={'URL': 'Images'}))\n",
    "    else:\n",
    "        print('Putting images from folder ' + im_dir + ' to dataframe\\n')\n",
    "        db['Image'] = (db['URL'].swifter.apply(putImageToDb_CV2, args=[im_dir])\n",
    "                       .dropna())\n",
    "    print('Finished checking folder\\n')\n",
    "    db['ID'] = db.groupby(['TYPE']).ngroup()\n",
    "    # print(db)\n",
    "    # db.set_index('Images', inplace=True)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _network\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHistory(history):\n",
    "    #val_acc = history.history['val_acc']\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "def createModel(df, dir, savename, columns,types_num, epo=10, batch=32):\n",
    "    DATASET_LOCATION = dir\n",
    "    BATCH_SIZE = batch\n",
    "    IMAGE_SIZE = (128, 128)\n",
    "    INPUT_SHAPE = (128, 128, 3)\n",
    "    EPOCHS = epo\n",
    "    conv_base = VGG19(weights = 'imagenet', include_top=False, input_shape = (128, 128, 3))\n",
    "    conv_base.trainable = False\n",
    "    # Tworzymy bazę na podstawie conv modelu bez górnego klasyfikatora\n",
    "    \n",
    "    # Instantiating a Convolutional Neural Network (CNN) Classifier\n",
    "    model = Sequential()\n",
    "    # biggest -----------\n",
    "    #--------vectoor\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "    # ------frozen base-------------\n",
    "    model.add(conv_base)\n",
    "    \n",
    "    #model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu', input_shape=INPUT_SHAPE))\n",
    "    #model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
    "    #model.add(MaxPooling2D(2, 2))\n",
    "    #model.add(Conv2D(64, (3, 3), activation= 'relu',padding='same'))\n",
    "    #model.add(Conv2D(64, (3, 3), activation= 'relu',padding='same'))\n",
    "    #model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    #model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(2, 2))\n",
    "    # conv_base.summary()\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    #model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(types_num, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.adam(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    print('Initialized model\\n')\n",
    "    # separate in training and testing\n",
    "    train_df, test_df = train_test_split(df, test_size=0.25, random_state=40)\n",
    "    # data augmentation - to provide more samples\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "    )\n",
    "    # cannot change validation data!\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "    print('Created data augmentation method, now we have more data! Cool huh?\\n')\n",
    "    # read files of a difrectory using flow from dataframe\n",
    "    # FIRST FOR TRAIN SECOND FOR TEST\n",
    "    try:\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "            train_df,\n",
    "            DATASET_LOCATION,\n",
    "            x_col=columns[0],\n",
    "            y_col=columns[1],\n",
    "            target_size=IMAGE_SIZE,\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        print('Created set for teaching\\n')\n",
    "        test_generator = test_datagen.flow_from_dataframe(\n",
    "            test_df,\n",
    "            DATASET_LOCATION,\n",
    "            x_col=columns[0],\n",
    "            y_col=columns[1],\n",
    "            target_size=IMAGE_SIZE,\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        print('Created set for validation\\n')\n",
    "        # NOW WE TRAIN THE MODEL\n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=test_df.shape[0] // BATCH_SIZE,\n",
    "            steps_per_epoch=train_df.shape[0] // BATCH_SIZE,\n",
    "            verbose=1,\n",
    "        )\n",
    "        print('Trained frozen model. Now unfroze some\\n')\n",
    "        set_trainable = False\n",
    "        for layer in conv_base.layers:\n",
    "            if layer.name == 'block5_conv1':\n",
    "                set_trainable = True\n",
    "            if set_trainable:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "                \n",
    "            \n",
    "        model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.RMSprop(lr=1e-5),\n",
    "        metrics=[\"accuracy\"],\n",
    "        )\n",
    "                \n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=test_df.shape[0] // BATCH_SIZE,\n",
    "            steps_per_epoch=train_df.shape[0] // BATCH_SIZE,\n",
    "            verbose=1,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Trained model\\n')\n",
    "        # save model and architecture to single file\n",
    "        model.save(savename)\n",
    "        print(\"Saved model to disk\\n\")\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(test_df, test_dir, name, columns):\n",
    "    IMAGE_SIZE = (128, 128)\n",
    "    INPUT_SHAPE = (128, 128, 3)\n",
    "    # load model\n",
    "    model = load_model(name)\n",
    "    print('Loaded the model\\n')\n",
    "    # summarize model.\n",
    "    model.summary()\n",
    "    # test generator\n",
    "    batches = 40\n",
    "    sample_test_generator = ImageDataGenerator(rescale=1.0/255).flow_from_dataframe(\n",
    "        test_df,\n",
    "        test_dir,\n",
    "        x_col=columns[0],\n",
    "        y_col=columns[1],\n",
    "        target_size=IMAGE_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=batches,\n",
    "    )\n",
    "    label_map = (sample_test_generator.class_indices)\n",
    "    print('Created test generator\\n')\n",
    "    # predict\n",
    "    filenames = sample_test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    #print('Len of filenames is:' + nb_samples)\n",
    "    predict = model.predict_generator(sample_test_generator,np.ceil(nb_samples/batches))\n",
    "    return predict, label_map\n",
    "    # score = model.evaluate_generator(sample_test_generator)\n",
    "    # print(\"Accuracy = \", score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/catalogMy.xlsx'\n",
    "test_dir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/new.xlsx'\n",
    "learnImDir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/Images'\n",
    "testImDir = 'D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/ImagesTest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking files and just putting their names in the dataframe\n",
      "\n",
      "Finished checking folder\n",
      "\n",
      "Downloading files and saving them in D:/Uni/SEMESTERS/MS/II/MonographicComputation/LAB/Paintings/Images\n",
      "\n",
      "Finished checking folder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPd = createImageDatabase(test_dir, testImDir, False)\n",
    "learnPd = createImageDatabase(dir, learnImDir, True, howmany = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn df is :\n",
      "                  Images          TYPE  ID\n",
      "0     aachen_adonis.jpg  mythological   4\n",
      "1   aachen_allegory.jpg  mythological   4\n",
      "2   aachen_allegorz.jpg  mythological   4\n",
      "3    aachen_antiope.jpg  mythological   4\n",
      "4     aachen_athena.jpg  mythological   4\n",
      "5    aachen_bacchus.jpg  mythological   4\n",
      "6   aachen_bacchus1.jpg  mythological   4\n",
      "7   aachen_davidbat.jpg    historical   1\n",
      "8       aachen_gods.jpg  mythological   4\n",
      "9      aachen_gods1.jpg  mythological   4\n",
      "10  aachen_j_couple.jpg         genre   0\n",
      "11  aachen_k_couple.jpg         genre   0\n",
      "12  aachen_portrai1.jpg      portrait   6\n",
      "13  aachen_portrai2.jpg      portrait   6\n",
      "14  aachen_portrai3.jpg      portrait   6\n",
      "15  aachen_portrai4.jpg         genre   0\n",
      "16   aachen_rudolf2.jpg      portrait   6\n",
      "17  aachen_selfpor1.jpg      portrait   6\n",
      "18  aachen_selfport.jpg      portrait   6\n",
      "19       aachen_war.jpg    historical   1\n",
      "Test df is :\n",
      "                 Images       TYPE  ID\n",
      "0      aimo_loreto.jpg  religious   7\n",
      "1    aimo_petronio.jpg  religious   7\n",
      "2   aimo_petronio1.jpg  religious   7\n",
      "3   aimo_petronio2.jpg  religious   7\n",
      "4    aimo_pope_leo.jpg  religious   7\n",
      "5       1_bustcoli.jpg   portrait   6\n",
      "6       1_innobus1.jpg   portrait   6\n",
      "7       1_innobus3.jpg   portrait   6\n",
      "8       1_innobus4.jpg   portrait   6\n",
      "9       1_laudivix.jpg   portrait   6\n",
      "10      1_santarel.jpg   portrait   6\n",
      "11      1_savenier.jpg   portrait   6\n",
      "12       1_zacchia.jpg   portrait   6\n",
      "13      2_frangip1.jpg   portrait   6\n",
      "14      2_frangip2.jpg   portrait   6\n",
      "15      2_frangip3.jpg   portrait   6\n",
      "16      2_frangip4.jpg   portrait   6\n",
      "17      2_franzon1.jpg   portrait   6\n",
      "18      2_franzon2.jpg   portrait   6\n",
      "19      2_franzon3.jpg   portrait   6\n"
     ]
    }
   ],
   "source": [
    "train_cols = ['Images','FORM']\n",
    "\n",
    "print('Learn df is :\\n', learnPd[['Images', 'TYPE', 'ID']].head(20))\n",
    "print('Test df is :\\n', testPd[['Images', 'TYPE', 'ID']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Images      FORM  ID\n",
      "0    aachen_adonis.jpg  painting   9\n",
      "1  aachen_allegory.jpg  painting   9\n",
      "2  aachen_allegorz.jpg  painting   9\n",
      "3   aachen_antiope.jpg  painting   9\n",
      "4    aachen_athena.jpg  painting   9\n",
      "{'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12}\n"
     ]
    }
   ],
   "source": [
    "db = learnPd.loc[:,train_cols]\n",
    "db['ID'] = db.groupby(train_cols[1]).ngroup()\n",
    "print(db.head())\n",
    "dic = (db.groupby(train_cols[1]).first())['ID'].to_dict()\n",
    "print(dic)\n",
    "types_num = len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model\n",
      "\n",
      "Created data augmentation method, now we have more data! Cool huh?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"Images\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7499 validated image filenames belonging to 13 classes.\n",
      "Created set for teaching\n",
      "\n",
      "Found 2500 validated image filenames belonging to 13 classes.\n",
      "Created set for validation\n",
      "\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 53s 286ms/step - loss: 0.7412 - accuracy: 0.7521 - val_loss: 0.5283 - val_accuracy: 0.8472\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 49s 261ms/step - loss: 0.5402 - accuracy: 0.8213 - val_loss: 0.6513 - val_accuracy: 0.8150\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 47s 254ms/step - loss: 0.4975 - accuracy: 0.8364 - val_loss: 0.5930 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 47s 250ms/step - loss: 0.4698 - accuracy: 0.8421 - val_loss: 0.8087 - val_accuracy: 0.8167\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 47s 253ms/step - loss: 0.4386 - accuracy: 0.8576 - val_loss: 0.9769 - val_accuracy: 0.8602\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 48s 254ms/step - loss: 0.4333 - accuracy: 0.8547 - val_loss: 0.3473 - val_accuracy: 0.8512\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 47s 249ms/step - loss: 0.4124 - accuracy: 0.8659 - val_loss: 0.3752 - val_accuracy: 0.8691\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 47s 251ms/step - loss: 0.4004 - accuracy: 0.8667 - val_loss: 0.2746 - val_accuracy: 0.8679\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 47s 251ms/step - loss: 0.4012 - accuracy: 0.8642 - val_loss: 0.1747 - val_accuracy: 0.8711\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 47s 253ms/step - loss: 0.3950 - accuracy: 0.8641 - val_loss: 0.2279 - val_accuracy: 0.8756\n",
      "Trained frozen model. Now unfroze some\n",
      "\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 48s 258ms/step - loss: 0.3454 - accuracy: 0.8878 - val_loss: 0.4020 - val_accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 47s 251ms/step - loss: 0.3294 - accuracy: 0.8864 - val_loss: 0.4958 - val_accuracy: 0.8772\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 47s 254ms/step - loss: 0.3208 - accuracy: 0.8912 - val_loss: 0.5609 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 46s 248ms/step - loss: 0.3240 - accuracy: 0.8915 - val_loss: 0.2008 - val_accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 49s 260ms/step - loss: 0.3350 - accuracy: 0.8894 - val_loss: 0.4423 - val_accuracy: 0.8797\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 52s 278ms/step - loss: 0.3218 - accuracy: 0.8897 - val_loss: 0.5731 - val_accuracy: 0.8797\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 49s 262ms/step - loss: 0.3168 - accuracy: 0.8927 - val_loss: 0.2230 - val_accuracy: 0.8772\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 47s 251ms/step - loss: 0.3255 - accuracy: 0.8902 - val_loss: 0.3663 - val_accuracy: 0.8789\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 46s 247ms/step - loss: 0.3128 - accuracy: 0.8945 - val_loss: 0.2554 - val_accuracy: 0.8768\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 48s 257ms/step - loss: 0.3121 - accuracy: 0.8970 - val_loss: 0.7063 - val_accuracy: 0.8801\n",
      "Trained model\n",
      "\n",
      "Saved model to disk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "history = createModel(learnPd, learnImDir,'from_imagenet_FORM.h5',train_cols,types_num, epo=10, batch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "printHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict, label_map_test = testModel(testPd, testImDir,'from_imagenet_FORM.h5',train_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 validated image filenames belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"Images\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "# check the indices and their categories on original dataset\n",
    "def check_orig_labels(learnPd, learnImDir ):\n",
    "    train_generator = ImageDataGenerator(rescale=1.0/255).flow_from_dataframe(\n",
    "            learnPd,\n",
    "            learnImDir,\n",
    "            x_col=train_cols[0],\n",
    "            y_col=train_cols[1],\n",
    "            target_size=(128,128,3),\n",
    "            class_mode=\"categorical\",\n",
    "        )\n",
    "    return (train_generator.class_indices)\n",
    "label_map_orig = check_orig_labels(learnPd, learnImDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12}\n",
      "{'architecture': 0, 'graphics': 1, 'illumination': 2, 'painting': 3, 'sculpture': 4}\n"
     ]
    }
   ],
   "source": [
    "print(label_map_orig)\n",
    "print(label_map_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12} {'architecture': 0, 'graphics': 4, 'illumination': 5, 'painting': 9, 'sculpture': 10}\n"
     ]
    }
   ],
   "source": [
    "def change_keys_from_org_to_new(label_map_orig,label_map_test):\n",
    "    res = {} \n",
    "    for key, val in label_map_test.items():\n",
    "        #label_map_test[key] = label_map_orig[key]\n",
    "        res[label_map_orig[key]] = key\n",
    "    print(label_map_orig,label_map_test)\n",
    "    return res\n",
    "\n",
    "final_dic = change_keys_from_org_to_new(label_map_orig,label_map_test  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'architecture', 4: 'graphics', 5: 'illumination', 9: 'painting', 10: 'sculpture'}\n"
     ]
    }
   ],
   "source": [
    "print(final_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 0, 'graphics': 1, 'illumination': 2, 'painting': 3, 'sculpture': 4}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-d656aa808b98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CATEGORY_PREDICTED'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'INDEX_PREDICTED'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfinal_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgood_checks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'INDEX_PREDICTED'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-153-d656aa808b98>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CATEGORY_PREDICTED'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'INDEX_PREDICTED'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfinal_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgood_checks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'INDEX_PREDICTED'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "test_check = testPd.loc[:,train_cols]\n",
    "test_check['ID'] = test_check.groupby(train_cols[1]).ngroup()\n",
    "\n",
    "max_index = np.argmax(predict, axis=-1)     \n",
    "test_check['INDEX_PREDICTED'] = max_index\n",
    "print(label_map)\n",
    "\n",
    "test_check['CATEGORY_PREDICTED'] = test_check['INDEX_PREDICTED'].apply(lambda x: final_dic[x])\n",
    "\n",
    "good_checks = test_check[test_check['INDEX_PREDICTED'] == test_check['ID']]\n",
    "print(good_checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 validated image filenames belonging to 13 classes.\n",
      "{'architecture': 0, 'ceramics': 1, 'furniture': 2, 'glassware': 3, 'graphics': 4, 'illumination': 5, 'metalwork': 6, 'mosaic': 7, 'others': 8, 'painting': 9, 'sculpture': 10, 'stained-glass': 11, 'tapestry': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\MyAnacondaDont\\envs\\tf-gpu-cuda8\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"Images\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_value = predict.max()\n",
    "print(max_value)\n",
    "max_index = np.argmax(predict, axis=-1)     \n",
    "print(max_index)\n",
    "print(len(max_index))\n",
    "test_check['INDEX_PREDICTED'] = max_index\n",
    "\n",
    "good_checks = test_check[test_check['INDEX_PREDICTED'] == test_check['ID']]\n",
    "print(good_checks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
